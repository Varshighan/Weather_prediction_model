{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897151a3",
   "metadata": {},
   "source": [
    "Step 1: Basic Time Features\n",
    "Extract from the time index:\n",
    "\n",
    "hour (0–23)\n",
    "\n",
    "day (1–31)\n",
    "\n",
    "month (1–12)\n",
    "\n",
    "dayofweek (0=Mon to 6=Sun)\n",
    "\n",
    "is_weekend (0/1)\n",
    "\n",
    "dayofyear (1–365)\n",
    "\n",
    "(optional) season (summer, monsoon, winter, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800bd536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "\n",
      "Processing time features for: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "Time features added and saved to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "input_dir = 'Dataset_cleaned/Tamil Nadu/Metrological Data/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"\\nProcessing time features for: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            header_lines = [next(f) for _ in range(3)]\n",
    "\n",
    "        df = pd.read_csv(file_path, skiprows=3)\n",
    "\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "\n",
    "        df['hour'] = df['time'].dt.hour\n",
    "        df['day'] = df['time'].dt.day\n",
    "        df['month'] = df['time'].dt.month\n",
    "        df['dayofweek'] = df['time'].dt.dayofweek\n",
    "        df['dayofyear'] = df['time'].dt.dayofyear\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            body = f.read()\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(header_lines)\n",
    "            f.write(body)\n",
    "\n",
    "        print(f\"Time features added and saved to: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60e758",
   "metadata": {},
   "source": [
    "Lag Features -  past behavior of temperature and rain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a43aa",
   "metadata": {},
   "source": [
    "| Lag Column                              | Meaning                     |\n",
    "| --------------------------------------- | --------------------------- |\n",
    "| `temp_lag_1h`                           | 1 hour ago temperature      |\n",
    "| `temp_lag_3h`, `6h`, `12h`, `24h`       | Multi-hour trends           |\n",
    "| `rain_lag_1h`, `3h`, `6h`, `12h`, `24h` | Rain history — super useful |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76877043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "\n",
      "Adding lag features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "Lag features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "input_dir = 'Dataset_cleaned/Tamil Nadu/Metrological Data/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "lag_hours = [1, 3, 6, 12, 24]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"\\nAdding lag features to: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            header_lines = [next(f) for _ in range(3)]\n",
    "\n",
    "        df = pd.read_csv(file_path, skiprows=3)\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "        for lag in lag_hours:\n",
    "            df[f'temp_lag_{lag}h'] = df['temperature_2m (°C)'].shift(lag)\n",
    "            df[f'rain_lag_{lag}h'] = df['rain (mm)'].shift(lag)\n",
    "\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            body = f.read()\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(header_lines)\n",
    "            f.write(body)\n",
    "\n",
    "        print(f\"Lag features added: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3bdae9",
   "metadata": {},
   "source": [
    "Rolling features - Capture short-term trends and volatility in temperature and rainfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ecffb4",
   "metadata": {},
   "source": [
    "| Rolling Column                         | Meaning                          |\n",
    "| -------------------------------------- | -------------------------------- |\n",
    "| `temp_roll_mean_6h`                    | Avg temp over past 6 hours       |\n",
    "| `temp_roll_mean_12h`, `24h`            | Longer averages                  |\n",
    "| `rain_roll_sum_6h`, `12h`, `24h`       | Total rainfall in last X hours   |\n",
    "| (optional later: rolling std/variance) | Spread/volatility — skip for now |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc9528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "\n",
      "Adding rolling features to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "Rolling features added: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'Dataset_cleaned/Tamil Nadu/Metrological Data/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "roll_windows = [6, 12, 24]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"\\nAdding rolling features to: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            header_lines = [next(f) for _ in range(3)]\n",
    "\n",
    "        df = pd.read_csv(file_path, skiprows=3)\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "        for window in roll_windows:\n",
    "            df[f'temp_roll_mean_{window}h'] = df['temperature_2m (°C)'].rolling(window=window).mean()\n",
    "            df[f'rain_roll_sum_{window}h'] = df['rain (mm)'].rolling(window=window).sum()\n",
    "\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "        with open(file_path, 'r') as f:\n",
    "            body = f.read()\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(header_lines)\n",
    "            f.write(body)\n",
    "\n",
    "        print(f\"Rolling features added: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b18b20",
   "metadata": {},
   "source": [
    "Step 4: Delta Features\n",
    "\n",
    "temp_diff_1h = temp - temp_lag_1h\n",
    "\n",
    "rain_diff_1h = rain - rain_lag_1h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b20985",
   "metadata": {},
   "source": [
    "Combined with the creation of the Global Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8b31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "Delta features and district column added for: Ariyalur\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "Delta features and district column added for: Chengalpattu\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "Delta features and district column added for: Chennai\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "Delta features and district column added for: Coimbatore\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "Delta features and district column added for: Cuddalore\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "Delta features and district column added for: Dindigul\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "Delta features and district column added for: Gummidipoondi\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "Delta features and district column added for: Hosur\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "Delta features and district column added for: Kanchipuram\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "Delta features and district column added for: Karur\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "Delta features and district column added for: Madurai\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "Delta features and district column added for: Nagapattinam\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "Delta features and district column added for: Ooty\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "Delta features and district column added for: Perundurai\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "Delta features and district column added for: Pudukottai\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "Delta features and district column added for: Ramanathapuram\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "Delta features and district column added for: Ranipet\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "Delta features and district column added for: Salem\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "Delta features and district column added for: Thanjavur\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "Delta features and district column added for: Thoothukudi\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "Delta features and district column added for: Tiruchirappalli\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "Delta features and district column added for: Tirunelveli\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "Delta features and district column added for: Tirupur\n",
      "\n",
      "Adding delta features: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "Delta features and district column added for: Vellore\n",
      "\n",
      "Global dataset saved as: weather_global_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'Dataset_cleaned/Tamil Nadu/Metrological Data/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "global_df_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"\\nAdding delta features: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            header_lines = [next(f) for _ in range(3)]\n",
    "\n",
    "        df = pd.read_csv(file_path, skiprows=3)\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "        df['temp_diff_1h'] = df['temperature_2m (°C)'] - df['temperature_2m (°C)'].shift(1)\n",
    "        df['rain_diff_1h'] = df['rain (mm)'] - df['rain (mm)'].shift(1)\n",
    "\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        district = os.path.basename(file_path).replace('_cleaned.csv', '')\n",
    "        df['district'] = district \n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "        with open(file_path, 'r') as f:\n",
    "            body = f.read()\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(header_lines)\n",
    "            f.write(body)\n",
    "\n",
    "        global_df_list.append(df)\n",
    "\n",
    "        print(f\"Delta features and district column added for: {district}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {file_path} — {e}\")\n",
    "\n",
    "global_df = pd.concat(global_df_list, ignore_index=True)\n",
    "global_df.to_csv('weather_global_dataset.csv', index=False)\n",
    "print(\"\\nGlobal dataset saved as: weather_global_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a18a45",
   "metadata": {},
   "source": [
    "Create Prediction Targets (t + 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fa418",
   "metadata": {},
   "source": [
    "| New Column    | Meaning                 |\n",
    "| ------------- | ----------------------- |\n",
    "| `target_temp` | temperature at `t+120h` |\n",
    "| `target_rain` | rainfall at `t+120h`    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c98f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "\n",
      "Creating prediction targets in: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "Targets added to: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "\n",
      "🌍 Updating global dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_23892\\4131655537.py:45: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  global_df = global_df.groupby('district').apply(shift_targets).dropna().reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global targets added and file updated.\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'Dataset_cleaned/Tamil Nadu/Metrological Data/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"\\nCreating prediction targets in: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            header_lines = [next(f) for _ in range(3)]\n",
    "\n",
    "        df = pd.read_csv(file_path, skiprows=3)\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "        df['target_temp'] = df['temperature_2m (°C)'].shift(-120)\n",
    "        df['target_rain'] = df['rain (mm)'].shift(-120)\n",
    "\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "        with open(file_path, 'r') as f:\n",
    "            body = f.read()\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(header_lines)\n",
    "            f.write(body)\n",
    "\n",
    "        print(f\"Targets added to: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {file_path}: {e}\")\n",
    "\n",
    "print(\"\\n🌍 Updating global dataset...\")\n",
    "global_df = pd.read_csv('weather_global_dataset.csv')\n",
    "global_df['time'] = pd.to_datetime(global_df['time'], errors='coerce')\n",
    "global_df = global_df.dropna(subset=['time'])\n",
    "global_df = global_df.sort_values(['district', 'time']).reset_index(drop=True)\n",
    "\n",
    "def shift_targets(group):\n",
    "    group = group.sort_values('time')\n",
    "    group['target_temp'] = group['temperature_2m (°C)'].shift(-120)\n",
    "    group['target_rain'] = group['rain (mm)'].shift(-120)\n",
    "    return group\n",
    "\n",
    "global_df = global_df.groupby('district').apply(shift_targets).dropna().reset_index(drop=True)\n",
    "global_df.to_csv('weather_global_dataset.csv', index=False)\n",
    "print(\"Global targets added and file updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae0478",
   "metadata": {},
   "source": [
    "Final Cleanup\n",
    "\n",
    "For each file (and the global file):\n",
    "\n",
    "Drop rows with any NaNs\n",
    "\n",
    "Optionally print the final shape and column list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc0539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ariyalur_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chengalpattu_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Chennai_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Coimbatore_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Cuddalore_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Dindigul_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Gummidipoondi_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Hosur_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Kanchipuram_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Karur_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Madurai_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Nagapattinam_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ooty_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Perundurai_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Pudukottai_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ramanathapuram_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Ranipet_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Salem_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thanjavur_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Thoothukudi_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tiruchirappalli_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirunelveli_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Tirupur_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleaning: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv\n",
      "Clean and saved: Dataset_cleaned/Tamil Nadu/Metrological Data\\Vellore_cleaned.csv — Shape: (8616, 35)\n",
      "\n",
      "Final cleanup: global dataset\n",
      "Global dataset ready — Shape: (206784, 35)\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'Dataset_cleaned/Tamil Nadu/Metrological Data/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"\\nFinal cleaning: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            header_lines = [next(f) for _ in range(3)]\n",
    "\n",
    "        df = pd.read_csv(file_path, skiprows=3)\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "        with open(file_path, 'r') as f:\n",
    "            body = f.read()\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(header_lines)\n",
    "            f.write(body)\n",
    "\n",
    "        print(f\"Clean and saved: {file_path} — Shape: {df.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {file_path}: {e}\")\n",
    "\n",
    "print(\"\\nFinal cleanup: global dataset\")\n",
    "global_df = pd.read_csv('weather_global_dataset.csv')\n",
    "global_df = global_df.dropna().reset_index(drop=True)\n",
    "global_df.to_csv('weather_global_dataset.csv', index=False)\n",
    "print(f\"Global dataset ready — Shape: {global_df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
